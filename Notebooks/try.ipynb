{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\baps\\AppData\\Local\\Temp\\ipykernel_6852\\2162656668.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\baps\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\baps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\baps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\baps\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import json\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers.legacy import SGD\n",
    "import random\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?', '!']\n",
    "data_file = open('data.json').read()\n",
    "intents = json.loads(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tag': 'greeting', 'patterns': ['Hi', 'Hello', 'Good day', 'Hey there'], 'responses': ['Hello! Welcome to the Child Advisor Chatbot. How can I assist you today?', 'Hi there! How can I help you?', 'Good day! What questions do you have for me?'], 'context_set': ''}\n",
      "Hi\n",
      "['Hi']\n",
      "Hello\n",
      "['Hello']\n",
      "Good day\n",
      "['Good', 'day']\n",
      "Hey there\n",
      "['Hey', 'there']\n",
      "{'tag': 'greetingMore', 'patterns': ['How are you', 'Whats up'], 'responses': ['I am fine!, How about you?', 'I am good, you?'], 'context_set': ''}\n",
      "How are you\n",
      "['How', 'are', 'you']\n",
      "Whats up\n",
      "['Whats', 'up']\n",
      "{'tag': 'goodbye', 'patterns': ['cya', 'Bye', 'See you later', 'Goodbye', 'I am Leaving', 'Have a Good day'], 'responses': ['Sad to see you go :(', 'Talk to you later', 'Goodbye!'], 'context_set': ''}\n",
      "cya\n",
      "['cya']\n",
      "Bye\n",
      "['Bye']\n",
      "See you later\n",
      "['See', 'you', 'later']\n",
      "Goodbye\n",
      "['Goodbye']\n",
      "I am Leaving\n",
      "['I', 'am', 'Leaving']\n",
      "Have a Good day\n",
      "['Have', 'a', 'Good', 'day']\n",
      "{'tag': 'info', 'patterns': ['How can I help my child with time management for school?'], 'responses': ['To help your child with time management, encourage them to create a schedule that includes dedicated time for homework, studying, and other activities. Teach them to prioritize tasks, break them down into smaller steps, and set realistic deadlines. Provide guidance and support as they learn to manage their time effectively.'], 'context_set': ''}\n",
      "How can I help my child with time management for school?\n",
      "['How', 'can', 'I', 'help', 'my', 'child', 'with', 'time', 'management', 'for', 'school', '?']\n",
      "{'tag': 'reading_skills', 'patterns': [\"What are some effective ways to improve my child's reading skills?\"], 'responses': [\"To improve your child's reading skills, encourage regular reading habits. Set aside time for reading each day, provide a variety of reading materials that match their interests and reading level, and discuss the books or articles they read. Consider using reading strategies like visualization, summarizing, and asking questions to enhance comprehension.\"], 'context_set': ''}\n",
      "What are some effective ways to improve my child's reading skills?\n",
      "['What', 'are', 'some', 'effective', 'ways', 'to', 'improve', 'my', 'child', \"'s\", 'reading', 'skills', '?']\n",
      "{'tag': 'organization', 'patterns': ['How can I encourage my child to be more organized with their schoolwork?'], 'responses': ['To encourage your child to be more organized, help them establish a system for keeping track of assignments, deadlines, and materials. Teach them to use tools like planners, calendars, or digital apps to stay organized. Set aside regular time to tidy up their study area and teach them the importance of keeping their materials in order.'], 'context_set': ''}\n",
      "How can I encourage my child to be more organized with their schoolwork?\n",
      "['How', 'can', 'I', 'encourage', 'my', 'child', 'to', 'be', 'more', 'organized', 'with', 'their', 'schoolwork', '?']\n",
      "{'tag': 'focus', 'patterns': ['What are some strategies to help my child stay focused while studying?'], 'responses': ['To help your child stay focused while studying, create a conducive environment free from distractions. Encourage them to break their study sessions into manageable chunks with short breaks in between. Teach them concentration techniques like mindfulness or deep breathing exercises. It can also be helpful to discuss goals and rewards to motivate their focus.'], 'context_set': ''}\n",
      "What are some strategies to help my child stay focused while studying?\n",
      "['What', 'are', 'some', 'strategies', 'to', 'help', 'my', 'child', 'stay', 'focused', 'while', 'studying', '?']\n",
      "{'tag': 'exam_preparation', 'patterns': ['How can I support my child in preparing for exams?'], 'responses': ['Supporting your child in preparing for exams involves creating a study plan together. Help them break down the material into smaller sections, set specific study goals, and practice with sample questions or past exams. Encourage them to review regularly rather than cramming at the last minute. Provide emotional support and reassurance during the exam period.'], 'context_set': ''}\n",
      "How can I support my child in preparing for exams?\n",
      "['How', 'can', 'I', 'support', 'my', 'child', 'in', 'preparing', 'for', 'exams', '?']\n",
      "documnets [(['Hi'], 'greeting'), (['Hello'], 'greeting'), (['Good', 'day'], 'greeting'), (['Hey', 'there'], 'greeting'), (['How', 'are', 'you'], 'greetingMore'), (['Whats', 'up'], 'greetingMore'), (['cya'], 'goodbye'), (['Bye'], 'goodbye'), (['See', 'you', 'later'], 'goodbye'), (['Goodbye'], 'goodbye'), (['I', 'am', 'Leaving'], 'goodbye'), (['Have', 'a', 'Good', 'day'], 'goodbye'), (['How', 'can', 'I', 'help', 'my', 'child', 'with', 'time', 'management', 'for', 'school', '?'], 'info'), (['What', 'are', 'some', 'effective', 'ways', 'to', 'improve', 'my', 'child', \"'s\", 'reading', 'skills', '?'], 'reading_skills'), (['How', 'can', 'I', 'encourage', 'my', 'child', 'to', 'be', 'more', 'organized', 'with', 'their', 'schoolwork', '?'], 'organization'), (['What', 'are', 'some', 'strategies', 'to', 'help', 'my', 'child', 'stay', 'focused', 'while', 'studying', '?'], 'focus'), (['How', 'can', 'I', 'support', 'my', 'child', 'in', 'preparing', 'for', 'exams', '?'], 'exam_preparation')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for intent in intents['intents']:\n",
    "    print(intent)\n",
    "    for pattern in intent['patterns']:\n",
    "        print(pattern)\n",
    "        \n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        print(w)\n",
    "        words.extend(w)\n",
    "        \n",
    "        documents.append((w, intent['tag']))\n",
    "\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])\n",
    "print(\"documnets\", documents)\n",
    "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "classes = sorted(list(set(classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pickle.dump(words, open('texts.pkl', 'wb'))\n",
    "pickle.dump(classes, open('labels.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0]], [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0]], [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0]], [[0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0]], [[1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1]], [[0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0]], [[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0]], [[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0]]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create our training data\n",
    "training = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # lemmatize each word - create base word, in attempt to represent related words\n",
    "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array with 1, if word match found in current pattern\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "    \n",
    "print(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for i in training:\n",
    "    train_x.append(i[0])\n",
    "    train_y.append(i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0]],\n",
       " [[0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 1, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 1, 0, 0, 0, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 1, 0, 0],\n",
       "  [0, 0, 0, 0, 0, 0, 0, 1],\n",
       "  [0, 0, 0, 0, 0, 0, 1, 0],\n",
       "  [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "  [1, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x,train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_x[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_x[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=((None,len(train_x[0]))), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_y[0]), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4/4 [==============================] - 1s 7ms/step - loss: 2.2053 - accuracy: 0.1176\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 2.2849 - accuracy: 0.1176\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.1137 - accuracy: 0.1765\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.0499 - accuracy: 0.2353\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.8486 - accuracy: 0.2353\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 1.7457 - accuracy: 0.4118\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.6599 - accuracy: 0.5294\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.5706 - accuracy: 0.4118\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6880 - accuracy: 0.4118\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.6046 - accuracy: 0.3529\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 1.3845 - accuracy: 0.4118\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.4054 - accuracy: 0.4706\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.4156 - accuracy: 0.4706\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2396 - accuracy: 0.6471\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.2889 - accuracy: 0.4706\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.0674 - accuracy: 0.5882\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 1.0001 - accuracy: 0.5882\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 1.1491 - accuracy: 0.5882\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 1.0313 - accuracy: 0.7059\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.8554 - accuracy: 0.7647\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 1.0068 - accuracy: 0.5882\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.8024 - accuracy: 0.7647\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 1.0528 - accuracy: 0.5294\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5646 - accuracy: 0.9412\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.9065 - accuracy: 0.5882\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.9273 - accuracy: 0.5882\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.6362 - accuracy: 0.8235\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.7074 - accuracy: 0.7647\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5260 - accuracy: 0.9412\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4600 - accuracy: 0.8824\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.5103 - accuracy: 0.9412\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4019 - accuracy: 0.9412\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.3573 - accuracy: 0.9412\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.4307 - accuracy: 0.8824\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.5776 - accuracy: 0.7059\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.8235\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.8235\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.4818 - accuracy: 0.8235\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.9412\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2309 - accuracy: 0.9412\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3598 - accuracy: 0.8824\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.3383 - accuracy: 0.9412\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4268 - accuracy: 0.9412\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.4106 - accuracy: 0.7059\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.3080 - accuracy: 0.9412\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2464 - accuracy: 0.9412\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1844 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1837 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.2551 - accuracy: 0.9412\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1781 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1136 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2531 - accuracy: 0.9412\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3147 - accuracy: 0.9412\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.0801 - accuracy: 0.9412\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1973 - accuracy: 0.9412\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1892 - accuracy: 0.9412\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1893 - accuracy: 0.9412\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.9412\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1764 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.2138 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0462 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0843 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1599 - accuracy: 0.9412\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1826 - accuracy: 0.8824\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1629 - accuracy: 0.9412\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0239 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.1624 - accuracy: 0.9412\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0738 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.3629 - accuracy: 0.9412\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0785 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.1205 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1198 - accuracy: 0.9412\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 0.4370 - accuracy: 0.7647\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0860 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0552 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.0559 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 0.1623 - accuracy: 0.9412\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0987 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0519 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2051 - accuracy: 0.8824\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.0637 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0840 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.2101 - accuracy: 0.9412\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.2268 - accuracy: 0.8824\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 0.0222 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0845 - accuracy: 0.9412\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.2889 - accuracy: 0.9412\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1345 - accuracy: 0.8824\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0776 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1121 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.0468 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 0.0453 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 0.0277 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 0.0860 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# fitting and saving the mode\n",
    "hist = model.fit(np.array(train_x),np.array(train_y), epochs=100, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.2053346633911133,\n",
       "  2.28485107421875,\n",
       "  2.113679885864258,\n",
       "  2.049891948699951,\n",
       "  1.8485511541366577,\n",
       "  1.7457221746444702,\n",
       "  1.6598678827285767,\n",
       "  1.5705758333206177,\n",
       "  1.6880080699920654,\n",
       "  1.6045950651168823,\n",
       "  1.384545087814331,\n",
       "  1.4053640365600586,\n",
       "  1.415578842163086,\n",
       "  1.2396072149276733,\n",
       "  1.2888516187667847,\n",
       "  1.0673917531967163,\n",
       "  1.000137209892273,\n",
       "  1.1490669250488281,\n",
       "  1.0313478708267212,\n",
       "  0.8554329872131348,\n",
       "  1.0067815780639648,\n",
       "  0.8024079203605652,\n",
       "  1.0527970790863037,\n",
       "  0.5645740628242493,\n",
       "  0.9064508080482483,\n",
       "  0.9273210763931274,\n",
       "  0.6361730694770813,\n",
       "  0.7074171900749207,\n",
       "  0.5259613990783691,\n",
       "  0.4599723815917969,\n",
       "  0.5103026032447815,\n",
       "  0.40186381340026855,\n",
       "  0.35730159282684326,\n",
       "  0.4306987226009369,\n",
       "  0.5776040554046631,\n",
       "  0.4841691255569458,\n",
       "  0.45477426052093506,\n",
       "  0.4817993938922882,\n",
       "  0.3277158737182617,\n",
       "  0.2308880090713501,\n",
       "  0.359752357006073,\n",
       "  0.3382529020309448,\n",
       "  0.4268151521682739,\n",
       "  0.41059425473213196,\n",
       "  0.3080200254917145,\n",
       "  0.246365487575531,\n",
       "  0.18440723419189453,\n",
       "  0.1837022751569748,\n",
       "  0.25509846210479736,\n",
       "  0.1781313270330429,\n",
       "  0.1136459931731224,\n",
       "  0.25308382511138916,\n",
       "  0.3146977424621582,\n",
       "  0.08009912073612213,\n",
       "  0.1972750723361969,\n",
       "  0.18923147022724152,\n",
       "  0.18932592868804932,\n",
       "  0.1168530285358429,\n",
       "  0.17638206481933594,\n",
       "  0.21376089751720428,\n",
       "  0.04619681090116501,\n",
       "  0.08431726694107056,\n",
       "  0.15988744795322418,\n",
       "  0.18260179460048676,\n",
       "  0.16289666295051575,\n",
       "  0.10980977863073349,\n",
       "  0.023942526429891586,\n",
       "  0.16239812970161438,\n",
       "  0.0738106518983841,\n",
       "  0.3629146218299866,\n",
       "  0.07846558839082718,\n",
       "  0.12047436833381653,\n",
       "  0.11983520537614822,\n",
       "  0.4370240867137909,\n",
       "  0.0860479548573494,\n",
       "  0.05517873167991638,\n",
       "  0.05590866133570671,\n",
       "  0.16232027113437653,\n",
       "  0.08460666984319687,\n",
       "  0.09868599474430084,\n",
       "  0.05192771926522255,\n",
       "  0.035433072596788406,\n",
       "  0.20510247349739075,\n",
       "  0.06371525675058365,\n",
       "  0.08383558690547943,\n",
       "  0.10069462656974792,\n",
       "  0.0840497836470604,\n",
       "  0.21009992063045502,\n",
       "  0.04455443099141121,\n",
       "  0.22676779329776764,\n",
       "  0.02223600260913372,\n",
       "  0.08453744649887085,\n",
       "  0.2888791561126709,\n",
       "  0.13453763723373413,\n",
       "  0.07763809710741043,\n",
       "  0.11209219694137573,\n",
       "  0.04675538092851639,\n",
       "  0.0452842079102993,\n",
       "  0.027734016999602318,\n",
       "  0.08600147813558578],\n",
       " 'accuracy': [0.11764705926179886,\n",
       "  0.11764705926179886,\n",
       "  0.1764705926179886,\n",
       "  0.23529411852359772,\n",
       "  0.23529411852359772,\n",
       "  0.4117647111415863,\n",
       "  0.529411792755127,\n",
       "  0.4117647111415863,\n",
       "  0.4117647111415863,\n",
       "  0.3529411852359772,\n",
       "  0.4117647111415863,\n",
       "  0.47058823704719543,\n",
       "  0.47058823704719543,\n",
       "  0.6470588445663452,\n",
       "  0.47058823704719543,\n",
       "  0.5882353186607361,\n",
       "  0.5882353186607361,\n",
       "  0.5882353186607361,\n",
       "  0.7058823704719543,\n",
       "  0.7647058963775635,\n",
       "  0.5882353186607361,\n",
       "  0.7647058963775635,\n",
       "  0.529411792755127,\n",
       "  0.9411764740943909,\n",
       "  0.5882353186607361,\n",
       "  0.5882353186607361,\n",
       "  0.8235294222831726,\n",
       "  0.7647058963775635,\n",
       "  0.9411764740943909,\n",
       "  0.8823529481887817,\n",
       "  0.9411764740943909,\n",
       "  0.9411764740943909,\n",
       "  0.9411764740943909,\n",
       "  0.8823529481887817,\n",
       "  0.7058823704719543,\n",
       "  0.8235294222831726,\n",
       "  0.8235294222831726,\n",
       "  0.8235294222831726,\n",
       "  0.9411764740943909,\n",
       "  0.9411764740943909,\n",
       "  0.8823529481887817,\n",
       "  0.9411764740943909,\n",
       "  0.9411764740943909,\n",
       "  0.7058823704719543,\n",
       "  0.9411764740943909,\n",
       "  0.9411764740943909,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9411764740943909,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9411764740943909,\n",
       "  0.9411764740943909,\n",
       "  0.9411764740943909,\n",
       "  0.9411764740943909,\n",
       "  0.9411764740943909,\n",
       "  0.9411764740943909,\n",
       "  0.9411764740943909,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9411764740943909,\n",
       "  0.8823529481887817,\n",
       "  0.9411764740943909,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9411764740943909,\n",
       "  1.0,\n",
       "  0.9411764740943909,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9411764740943909,\n",
       "  0.7647058963775635,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9411764740943909,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.8823529481887817,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9411764740943909,\n",
       "  1.0,\n",
       "  0.8823529481887817,\n",
       "  1.0,\n",
       "  0.9411764740943909,\n",
       "  0.9411764740943909,\n",
       "  0.8823529481887817,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\baps\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"chatModel.h5\",hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "newModel = tf.keras.models.load_model(\"chatModel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.engine.sequential.Sequential at 0x1a4317c1c60>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('chatModel.h5')\n",
    "intents = json.loads(open('data.json').read())\n",
    "words = pickle.load(open('texts.pkl', 'rb'))\n",
    "classes = pickle.load(open('labels.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow(sentence, words, show_details=True):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0] * len(words)\n",
    "    for s in sentence_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == s:\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print(\"found in bag: %s\" % w)\n",
    "    return np.array(bag) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(sentence, model):\n",
    "    p = bow(sentence, words, show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getResponse(ints, intents_json):\n",
    "    tag = ints[0]['intent']\n",
    "    list_of_intents = intents_json['intents']\n",
    "    for i in list_of_intents:\n",
    "        if i['tag'] == tag:\n",
    "            result = random.choice(i['responses'])\n",
    "            break\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chatbot_response(msg):\n",
    "    ints = predict_class(msg, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 116ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi there! How can I help you?'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Good day! What questions do you have for me?'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 52ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! Welcome to the Child Advisor Chatbot. How can I assist you today?'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am fine!, How about you?'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"how are you ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 120ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am good, you?'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"whats going on?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Talk to you later'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"who is prime minister of india?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sad to see you go :('"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"who made you ? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 114ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am good, you?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot_response(\"what are you up to ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array([1,2,3,4,5])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3, 4, 5])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[arr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([arr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
